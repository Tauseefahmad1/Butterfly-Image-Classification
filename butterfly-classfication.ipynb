{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54f7e20-c0b9-440b-b61e-0ca6a157aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Training_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0fcbf5e-58ab-490b-b4d0-0ad972e903ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,shutil\n",
    "import numpy as np\n",
    "from_dir = os.getcwd()+\"/\"+\"train\"\n",
    "for i in np.unique(df[\"label\"]).tolist():\n",
    "    if not os.path.isdir(from_dir+\"/\" +i):\n",
    "        os.mkdir(from_dir+\"/\" +i)\n",
    "        \n",
    "for i in os.listdir(from_dir):\n",
    "    if \".jpg\" in i:\n",
    "        shutil.copy(from_dir+\"/\" +i,from_dir +\"/\" +df[df[\"filename\"]==i][\"label\"].tolist()[0]+\"/\"+i)\n",
    "        os.remove(from_dir+\"/\" +i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61bc3ad0-3b76-4b88-b01a-b122fe067e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# for i in os.listdir(os.getcwd()+\"/\"+\"train\"):\n",
    "#     if os.path.isdir(os.getcwd()+\"/\"+\"train\"):\n",
    "#         for j in os.listdir(os.getcwd()+\"/\"+\"train\"+\"/\"+i):\n",
    "#             img = cv2.imread(os.getcwd()+\"/\"+\"train\"+\"/\"+i+\"/\"+j)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,        # 隨機旋轉的角度範圍\n",
    "    width_shift_range=0.3,    # 水平方向隨機平移的範圍\n",
    "    height_shift_range=0.3,   # 垂直方向隨機平移的範圍\n",
    "    shear_range=0.3,          # 剪切強度 (shear transformation)\n",
    "    zoom_range=0.3,           # 隨機縮放的範圍\n",
    "    horizontal_flip=True,     # 水平翻轉\n",
    "    brightness_range=[0.8, 1.2]  # 亮度調整範圍\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26408336-07d2-48e9-b0a2-8e1f0bab83a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5225 images belonging to 75 classes.\n",
      "Found 1274 images belonging to 75 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from_dir = os.getcwd()+\"/\"+\"train\"\n",
    "source_path = from_dir\n",
    "# train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#         source_path,\n",
    "#         label_mode ='categorical',\n",
    "#         color_mode = 'rgb',\n",
    "#         batch_size = 32,\n",
    "#         image_size = (224, 224),\n",
    "#         shuffle=True,\n",
    "#         seed = 13,\n",
    "#         validation_split = 0.2,\n",
    "#         subset='training'\n",
    "#     )\n",
    "# valid_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#         source_path,\n",
    "#         label_mode ='categorical',\n",
    "#         color_mode = 'rgb',\n",
    "#         batch_size = 32,\n",
    "#         image_size = (224, 224),\n",
    "#         shuffle=True,\n",
    "#         seed = 13,\n",
    "#         validation_split = 0.2,\n",
    "#         subset='validation'\n",
    "#     )\n",
    "# # \n",
    "image_size = (224, 224)\n",
    "batch_size = 128\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                            shear_range = 0.2,\n",
    "                            zoom_range = 0.2,\n",
    "                            width_shift_range=0.2,\n",
    "                            height_shift_range=0.2,\n",
    "                            rotation_range = 5,\n",
    "                            horizontal_flip = True,\n",
    "                            # vertical_flip = True,\n",
    "                            validation_split = 0.2)\n",
    "\n",
    "train_ds = train_datagen.flow_from_directory(source_path,\n",
    "                                      target_size = image_size,\n",
    "                                      batch_size = batch_size,\n",
    "                                      class_mode = 'sparse',\n",
    "                                      subset = 'training',\n",
    "                                      color_mode=\"rgb\",\n",
    "                                      shuffle=True)\n",
    "\n",
    "val_ds = train_datagen.flow_from_directory(source_path,\n",
    "                                      target_size = image_size,\n",
    "                                      batch_size = batch_size,\n",
    "                                      class_mode = 'sparse',\n",
    "                                      subset = 'validation',\n",
    "                                      color_mode=\"rgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbe52cc7-c17d-44f8-b53b-1a084fbfdf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten\n",
    "from keras.utils import np_utils\n",
    "vgg_base = applications.VGG19(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\n",
    "vgg_base.trainable = False\n",
    "def create_model():\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(224, 224, 3)),\n",
    "        # tf.keras.layers.experimental.preprocessing.Rescaling(1/255, input_shape=(224, 224, 3)),\n",
    "        vgg_base,\n",
    "        # tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "        # tf.keras.layers.MaxPooling2D(2,2),\n",
    "        # tf.keras.layers.MaxPooling2D(2,2),\n",
    "        # tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        # tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
    "        # tf.keras.layers.MaxPooling2D(2,2),\n",
    "        # tf.keras.layers.MaxPooling2D(2,2),\n",
    "        # tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "        # tf.keras.layers.MaxPooling2D(2,2),\n",
    "        # tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
    "        # tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        # tf.keras.layers.Dense(32, activation='relu'),\n",
    "        # tf.keras.layers.Dropout(0.3),\n",
    "        # tf.keras.layers.Dense(512, activation='relu'),\n",
    "        # tf.keras.layers.Dropout(0.3),\n",
    "        # tf.keras.layers.Dropout(0.1),\n",
    "        # tf.keras.layers.Dense(2048, activation='relu'),\n",
    "        # tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(1024, activation='elu'),\n",
    "        # tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(75, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e80d6bd-f702-4bf7-a512-eac3257219cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 7, 7, 512)         20024384  \n",
      "                                                                 \n",
      " global_average_pooling2d_3  (None, 512)               0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 75)                76875     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20626571 (78.68 MB)\n",
      "Trainable params: 602187 (2.30 MB)\n",
      "Non-trainable params: 20024384 (76.39 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.build(input_shape=(None, 224, 224, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e79f289-a145-4b04-ac6a-5615cac7f1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 158s 4s/step - loss: 3.8939 - accuracy: 0.1470 - val_loss: 3.1703 - val_accuracy: 0.3273\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 156s 4s/step - loss: 2.6869 - accuracy: 0.4285 - val_loss: 2.1846 - val_accuracy: 0.5228\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 1.9598 - accuracy: 0.5661 - val_loss: 1.6762 - val_accuracy: 0.6248\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 1.5601 - accuracy: 0.6387 - val_loss: 1.4115 - val_accuracy: 0.6625\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 1.3233 - accuracy: 0.6827 - val_loss: 1.2581 - val_accuracy: 0.6954\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 1.1753 - accuracy: 0.7043 - val_loss: 1.1516 - val_accuracy: 0.6970\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 1.0759 - accuracy: 0.7275 - val_loss: 1.0607 - val_accuracy: 0.7221\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.9855 - accuracy: 0.7520 - val_loss: 0.9783 - val_accuracy: 0.7441\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.9171 - accuracy: 0.7596 - val_loss: 0.9437 - val_accuracy: 0.7496\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.8567 - accuracy: 0.7713 - val_loss: 0.9218 - val_accuracy: 0.7551\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.8175 - accuracy: 0.7858 - val_loss: 0.8931 - val_accuracy: 0.7575\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.7519 - accuracy: 0.8046 - val_loss: 0.8129 - val_accuracy: 0.7841\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.7281 - accuracy: 0.8077 - val_loss: 0.8565 - val_accuracy: 0.7582\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.6827 - accuracy: 0.8197 - val_loss: 0.8695 - val_accuracy: 0.7630\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.6774 - accuracy: 0.8103 - val_loss: 0.8026 - val_accuracy: 0.7943\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.6535 - accuracy: 0.8170 - val_loss: 0.7921 - val_accuracy: 0.7998\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.6099 - accuracy: 0.8279 - val_loss: 0.7755 - val_accuracy: 0.7889\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.6033 - accuracy: 0.8352 - val_loss: 0.7603 - val_accuracy: 0.7904\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.5851 - accuracy: 0.8360 - val_loss: 0.7475 - val_accuracy: 0.7889\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.5647 - accuracy: 0.8387 - val_loss: 0.7517 - val_accuracy: 0.8053\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.5431 - accuracy: 0.8509 - val_loss: 0.7501 - val_accuracy: 0.7873\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.5307 - accuracy: 0.8530 - val_loss: 0.7287 - val_accuracy: 0.7904\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 154s 4s/step - loss: 0.5268 - accuracy: 0.8496 - val_loss: 0.7200 - val_accuracy: 0.7951\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.4939 - accuracy: 0.8605 - val_loss: 0.7277 - val_accuracy: 0.7889\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.4861 - accuracy: 0.8580 - val_loss: 0.7140 - val_accuracy: 0.7967\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.4566 - accuracy: 0.8674 - val_loss: 0.6681 - val_accuracy: 0.8148\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 154s 4s/step - loss: 0.4631 - accuracy: 0.8651 - val_loss: 0.7233 - val_accuracy: 0.7983\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.4458 - accuracy: 0.8741 - val_loss: 0.7339 - val_accuracy: 0.8006\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 154s 4s/step - loss: 0.4505 - accuracy: 0.8662 - val_loss: 0.7529 - val_accuracy: 0.7865\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.4246 - accuracy: 0.8760 - val_loss: 0.7083 - val_accuracy: 0.8022\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.4242 - accuracy: 0.8720 - val_loss: 0.7262 - val_accuracy: 0.8006\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.4033 - accuracy: 0.8808 - val_loss: 0.7079 - val_accuracy: 0.8014\n",
      "Epoch 33/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.3922 - accuracy: 0.8871 - val_loss: 0.7048 - val_accuracy: 0.8108\n",
      "Epoch 34/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.4029 - accuracy: 0.8766 - val_loss: 0.6826 - val_accuracy: 0.8093\n",
      "Epoch 35/100\n",
      "41/41 [==============================] - 155s 4s/step - loss: 0.3938 - accuracy: 0.8827 - val_loss: 0.7034 - val_accuracy: 0.8046\n",
      "Epoch 36/100\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3895 - accuracy: 0.8859"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    "    start_from_epoch=0,\n",
    ")\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=100,shuffle=True,callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099877b6-e84e-442c-91e4-621d5e9d3ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "model.save(os.getcwd()+\"/\"+\"models/model_VGG19 \"+datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b72052-599a-4c44-a885-3814a8b3e6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef53dd-0853-4b75-a709-af303701ae35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
